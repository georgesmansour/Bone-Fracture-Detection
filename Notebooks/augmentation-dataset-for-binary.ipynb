{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nos.makedirs('/kaggle/working/augmented-dataset-binary-test/positive/', exist_ok=True)\nos.makedirs('/kaggle/working/augmented-dataset-binary-test/negative/', exist_ok=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-27T18:52:09.883854Z","iopub.execute_input":"2023-02-27T18:52:09.884669Z","iopub.status.idle":"2023-02-27T18:52:09.923677Z","shell.execute_reply.started":"2023-02-27T18:52:09.884603Z","shell.execute_reply":"2023-02-27T18:52:09.922435Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install keras-preprocessing","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:09.925551Z","iopub.execute_input":"2023-02-27T18:52:09.925910Z","iopub.status.idle":"2023-02-27T18:52:22.552744Z","shell.execute_reply.started":"2023-02-27T18:52:09.925875Z","shell.execute_reply":"2023-02-27T18:52:22.548898Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting keras-preprocessing\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m332.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-preprocessing) (1.21.6)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.7/site-packages (from keras-preprocessing) (1.16.0)\nInstalling collected packages: keras-preprocessing\nSuccessfully installed keras-preprocessing-1.1.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:22.555826Z","iopub.execute_input":"2023-02-27T18:52:22.556222Z","iopub.status.idle":"2023-02-27T18:52:31.937429Z","shell.execute_reply.started":"2023-02-27T18:52:22.556185Z","shell.execute_reply":"2023-02-27T18:52:31.936291Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"def normal_copy_image(image=[],location=\"\"):\n    datagen = ImageDataGenerator()\n    datagen.fit(image)\n    \n    \n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n\n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n         save_prefix='n',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:31.940822Z","iopub.execute_input":"2023-02-27T18:52:31.941954Z","iopub.status.idle":"2023-02-27T18:52:31.948707Z","shell.execute_reply.started":"2023-02-27T18:52:31.941908Z","shell.execute_reply":"2023-02-27T18:52:31.947540Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def all_params_image(image=[],location=\"\"):\n    \n    datagen = ImageDataGenerator(rotation_range =15, \n                         width_shift_range = 0.2, \n                         height_shift_range = 0.2,  \n                         rescale=1./255, \n                         shear_range=0.2, \n                         zoom_range=0.2, \n                         horizontal_flip = True, \n                         vertical_flip = True,\n                         fill_mode = 'nearest', \n                         data_format='channels_last', \n                         brightness_range=[0.5, 1.5]) \n    \n    datagen.fit(image)\n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n    \n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n         save_prefix='all',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:31.950138Z","iopub.execute_input":"2023-02-27T18:52:31.950697Z","iopub.status.idle":"2023-02-27T18:52:31.964581Z","shell.execute_reply.started":"2023-02-27T18:52:31.950637Z","shell.execute_reply":"2023-02-27T18:52:31.963270Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def rotation_image(image=[],location=\"\"):\n    \n    datagen = ImageDataGenerator()\n    datagen.fit(image)\n    \n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n    \n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n         save_prefix='rot',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:31.967901Z","iopub.execute_input":"2023-02-27T18:52:31.968889Z","iopub.status.idle":"2023-02-27T18:52:31.980471Z","shell.execute_reply.started":"2023-02-27T18:52:31.968830Z","shell.execute_reply":"2023-02-27T18:52:31.979118Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def flip_image(image=[],location=\"\"):\n    \n    datagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\n    datagen.fit(image)\n    \n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n    \n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n        save_prefix='flip',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:31.982123Z","iopub.execute_input":"2023-02-27T18:52:31.983819Z","iopub.status.idle":"2023-02-27T18:52:31.992088Z","shell.execute_reply.started":"2023-02-27T18:52:31.983749Z","shell.execute_reply":"2023-02-27T18:52:31.990776Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def zoom_image(image=[],location=\"\"):\n    \n    datagen = ImageDataGenerator(zoom_range=0.5) \n    datagen.fit(image)\n    \n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n    \n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n        save_prefix='z',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:31.993286Z","iopub.execute_input":"2023-02-27T18:52:31.994032Z","iopub.status.idle":"2023-02-27T18:52:32.011553Z","shell.execute_reply.started":"2023-02-27T18:52:31.993987Z","shell.execute_reply":"2023-02-27T18:52:32.010071Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def brightness_image(image=[],location=\"\"):\n    \n    datagen = ImageDataGenerator(brightness_range=[0.7, 1.3]) \n    datagen.fit(image)\n    \n    save_dir = '/kaggle/working/augmented-dataset-binary/'+location\n    \n    for x, val in zip(datagen.flow(image,                    #image we chose\n        save_to_dir=save_dir,     #this is where we figure out where to save\n        save_prefix='bri',        # it will save the images as 'aug_0912' some number for every new augmented image\n        save_format='png'),range(0)) :     # here we define a range because we want 10 augmented images otherwise it will keep looping forever I think\n        pass\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:32.015689Z","iopub.execute_input":"2023-02-27T18:52:32.016397Z","iopub.status.idle":"2023-02-27T18:52:32.025039Z","shell.execute_reply.started":"2023-02-27T18:52:32.016362Z","shell.execute_reply":"2023-02-27T18:52:32.023102Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Positve","metadata":{}},{"cell_type":"code","source":"import os\n\nos.makedirs('/kaggle/working/augmented-dataset-binary/positive/', exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:32.027189Z","iopub.execute_input":"2023-02-27T18:52:32.031027Z","iopub.status.idle":"2023-02-27T18:52:32.037616Z","shell.execute_reply.started":"2023-02-27T18:52:32.030977Z","shell.execute_reply":"2023-02-27T18:52:32.036130Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# copy the images\nimport keras\nimport cv2\nimport os\nimport glob\nfrom keras_preprocessing.image.utils import img_to_array,array_to_img, load_img\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# datagen = ImageDataGenerator() \nimg_dir = \"/kaggle/input/augmentation-dataset-binary/binary_dataset/positive\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\ndata = []\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.cvtColor(img, cv2.cv2.COLOR_BGR2GRAY)\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    data.append(x)\n\n\ni = 0\npath, dirs, files = next(os.walk(\"/kaggle/input/augmentation-dataset-binary/binary_dataset/positive\"))\nfile_count = len(files) #to find number of files in folder\n\nfor x in data:\n    normal_copy_image(image=x,location=\"positive\")  #normal copy\n    all_params_image(image=x,location=\"positive\") #all params copy\n    flip_image(image=x,location=\"positive\") #horizontal vertical\n    zoom_image(image=x,location=\"positive\") # zoom image\n    brightness_image(image=x,location=\"positive\") #brightness\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:52:32.040202Z","iopub.execute_input":"2023-02-27T18:52:32.041131Z","iopub.status.idle":"2023-02-27T18:53:12.624188Z","shell.execute_reply.started":"2023-02-27T18:52:32.041089Z","shell.execute_reply":"2023-02-27T18:53:12.622832Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"libpng warning: Incorrect bKGD chunk length\nlibpng warning: Incorrect bKGD chunk length\n","output_type":"stream"}]},{"cell_type":"code","source":"#augmentation with 60 degrees rotation\n\nimport keras\nimport cv2\nimport os\nimport glob\n\nfrom keras_preprocessing.image.utils import img_to_array,array_to_img, load_img\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator()\n\nimg_dir = \"/kaggle/input/augmentation-dataset-binary/binary_dataset/positive\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\ndata = []\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.cvtColor(img, cv2.cv2.COLOR_BGR2GRAY)\n    height, width = img.shape[:2]\n    matrix = cv2.getRotationMatrix2D((width/2, height/2), 60, 1)\n    img_rotated = cv2.warpAffine(img, matrix, (width, height))\n    x= img_to_array(img_rotated)\n    x = x.reshape((1,) + x.shape)\n    data.append(x)\n    \n\n\ni = 0\npath, dirs, files = next(os.walk(\"/kaggle/input/augmentation-dataset-binary/binary_dataset/positive\"))\nfile_count = len(files) #to find number of files in folder\n\nfor x in data:\n    rotation_image(image=x,location=\"positive\")","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:12.625551Z","iopub.execute_input":"2023-02-27T18:53:12.625899Z","iopub.status.idle":"2023-02-27T18:53:19.373189Z","shell.execute_reply.started":"2023-02-27T18:53:12.625868Z","shell.execute_reply":"2023-02-27T18:53:19.371485Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stderr","text":"libpng warning: Incorrect bKGD chunk length\nlibpng warning: Incorrect bKGD chunk length\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\nsource_dir = '/kaggle/working/augmented-dataset-binary/positive/'\ndest_dir = '/kaggle/working/augmented-dataset-binary-test/positive/'\n\nfiles = os.listdir(source_dir)\nrandom.shuffle(files)\nnum_test_files = int(len(files)*0.15)\n\n\n\nrandom_test_files  = random.sample(files, num_test_files)\n\nfor file in random_test_files:\n    file_path = os.path.join(source_dir, file)\n    dest_path = os.path.join(dest_dir, file)\n    shutil.move(file_path, dest_path)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:19.374892Z","iopub.execute_input":"2023-02-27T18:53:19.375261Z","iopub.status.idle":"2023-02-27T18:53:19.390686Z","shell.execute_reply.started":"2023-02-27T18:53:19.375225Z","shell.execute_reply":"2023-02-27T18:53:19.388846Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"import os\n# FOLDER_PATH = 'positive/'\n# ROOT_PATH = '/kaggle/working/augmented-dataset/\nprint(len(os.listdir('/kaggle/working/augmented-dataset-binary/positive/')))","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:19.392568Z","iopub.execute_input":"2023-02-27T18:53:19.393123Z","iopub.status.idle":"2023-02-27T18:53:19.402366Z","shell.execute_reply.started":"2023-02-27T18:53:19.393076Z","shell.execute_reply":"2023-02-27T18:53:19.400611Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"1081\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/augmented-dataset-binary-test/positive/')))","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:19.404094Z","iopub.execute_input":"2023-02-27T18:53:19.404441Z","iopub.status.idle":"2023-02-27T18:53:19.411154Z","shell.execute_reply.started":"2023-02-27T18:53:19.404406Z","shell.execute_reply":"2023-02-27T18:53:19.409825Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"190\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Negative","metadata":{}},{"cell_type":"code","source":"import os\n\nos.makedirs('/kaggle/working/augmented-dataset-binary/negative/', exist_ok=True)\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:19.413311Z","iopub.execute_input":"2023-02-27T18:53:19.413730Z","iopub.status.idle":"2023-02-27T18:53:19.421457Z","shell.execute_reply.started":"2023-02-27T18:53:19.413684Z","shell.execute_reply":"2023-02-27T18:53:19.420184Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# copy the images\n\nimport keras\nimport cv2\nimport os\nimport glob\nfrom keras_preprocessing.image.utils import img_to_array,array_to_img, load_img\nfrom keras.preprocessing.image import ImageDataGenerator\n\n# datagen = ImageDataGenerator() \nimg_dir = \"/kaggle/input/augmentation-dataset-binary/binary_dataset/negative\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\ndata = []\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.cvtColor(img, cv2.cv2.COLOR_BGR2GRAY)\n    x = img_to_array(img)\n    x = x.reshape((1,) + x.shape)\n    data.append(x)\n\n\ni = 0\npath, dirs, files = next(os.walk(\"/kaggle/input/augmentation-dataset-binary/binary_dataset/negative\"))\nfile_count = len(files) #to find number of files in folder\n\nfor x in data:\n    normal_copy_image(image=x,location=\"negative\")  #normal copy\n    all_params_image(image=x,location=\"negative\") #all params copy\n    flip_image(image=x,location=\"negative\") #horizontal vertical\n    zoom_image(image=x,location=\"negative\") # zoom image\n    brightness_image(image=x,location=\"negative\") #brightness\n\n","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:19.423777Z","iopub.execute_input":"2023-02-27T18:53:19.424286Z","iopub.status.idle":"2023-02-27T18:53:43.069602Z","shell.execute_reply.started":"2023-02-27T18:53:19.424243Z","shell.execute_reply":"2023-02-27T18:53:43.068061Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#augmentation with 60 degrees rotation\n\nimport keras\nimport cv2\nimport os\nimport glob\n\nfrom keras_preprocessing.image.utils import img_to_array,array_to_img, load_img\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator()\n\nimg_dir = \"/kaggle/input/augmentation-dataset-binary/binary_dataset/negative\"\ndata_path = os.path.join(img_dir,'*g')\nfiles = glob.glob(data_path)\ndata = []\nfor f1 in files:\n    img = cv2.imread(f1)\n    img = cv2.cvtColor(img, cv2.cv2.COLOR_BGR2GRAY)\n    height, width = img.shape[:2]\n    matrix = cv2.getRotationMatrix2D((width/2, height/2), 60, 1)\n    img_rotated = cv2.warpAffine(img, matrix, (width, height))\n    x= img_to_array(img_rotated)\n    x = x.reshape((1,) + x.shape)\n    data.append(x)\n    \n\n\ni = 0\npath, dirs, files = next(os.walk(\"/kaggle/input/augmentation-dataset-binary/binary_dataset/negative\"))\nfile_count = len(files) #to find number of files in folder\n\nfor x in data:\n    rotation_image(image=x,location=\"negative\")","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:43.071010Z","iopub.execute_input":"2023-02-27T18:53:43.071375Z","iopub.status.idle":"2023-02-27T18:53:46.773308Z","shell.execute_reply.started":"2023-02-27T18:53:43.071338Z","shell.execute_reply":"2023-02-27T18:53:46.772181Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import os\nimport shutil\nimport random\n\nsource_dir = '/kaggle/working/augmented-dataset-binary/negative/'\ndest_dir = '/kaggle/working/augmented-dataset-binary-test/negative/'\n\nfiles = os.listdir(source_dir)\nrandom.shuffle(files)\nnum_test_files = int(len(files)*0.15)\n\n\n\nrandom_test_files  = random.sample(files, num_test_files)\n\nfor file in random_test_files:\n    file_path = os.path.join(source_dir, file)\n    dest_path = os.path.join(dest_dir, file)\n    shutil.move(file_path, dest_path)","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:46.775261Z","iopub.execute_input":"2023-02-27T18:53:46.775742Z","iopub.status.idle":"2023-02-27T18:53:46.790027Z","shell.execute_reply.started":"2023-02-27T18:53:46.775694Z","shell.execute_reply":"2023-02-27T18:53:46.788518Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"import os\n# FOLDER_PATH = 'positive/'\n# ROOT_PATH = '/kaggle/working/augmented-dataset/\nprint(len(os.listdir('/kaggle/working/augmented-dataset-binary/negative/')))","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:46.791775Z","iopub.execute_input":"2023-02-27T18:53:46.792113Z","iopub.status.idle":"2023-02-27T18:53:46.799959Z","shell.execute_reply.started":"2023-02-27T18:53:46.792078Z","shell.execute_reply":"2023-02-27T18:53:46.798181Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1087\n","output_type":"stream"}]},{"cell_type":"code","source":"print(len(os.listdir('/kaggle/working/augmented-dataset-binary-test/negative/')))","metadata":{"execution":{"iopub.status.busy":"2023-02-27T18:53:46.801847Z","iopub.execute_input":"2023-02-27T18:53:46.802459Z","iopub.status.idle":"2023-02-27T18:53:46.812192Z","shell.execute_reply.started":"2023-02-27T18:53:46.802417Z","shell.execute_reply":"2023-02-27T18:53:46.810222Z"},"trusted":true},"execution_count":21,"outputs":[{"name":"stdout","text":"191\n","output_type":"stream"}]}]}